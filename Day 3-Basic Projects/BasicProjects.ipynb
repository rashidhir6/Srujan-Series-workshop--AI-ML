{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST DATASET FOR DIGIT RECOGNITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'> <class 'tuple'> <class 'tuple'>\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "2 2 2\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(50000, 784) (10000, 784) (10000, 784)\n",
      "(50000,) (10000,) (10000,)\n",
      "Iteration 1, loss = 0.63087646\n",
      "Iteration 2, loss = 0.34111379\n",
      "Iteration 3, loss = 0.32001603\n",
      "Iteration 4, loss = 0.30255489\n",
      "Iteration 5, loss = 0.29051612\n",
      "Iteration 6, loss = 0.28064002\n",
      "Iteration 7, loss = 0.27996021\n",
      "Iteration 8, loss = 0.27430856\n",
      "Iteration 9, loss = 0.27090146\n",
      "Iteration 10, loss = 0.26721353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hrituja\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### Predictions #################\n",
      "[7 2 1 ... 4 5 6]\n",
      "#############################################\n",
      "Accuracy = 0.9294\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e75a171baa97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#############################################\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy =\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestsettarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy \n",
    "from sklearn import metrics \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle\n",
    " #load data from a pickle file. #if you are unsure what is inside pkl file (typically available in readme), see the type of return value and further drill down \n",
    "train_set, valid_set, test_set = pickle.load(open('C:\\ProgramData\\Anaconda3\\datasets\\mnist.pkl','rb'),encoding='latin1')\n",
    " #drill down\n",
    "print(type(train_set), type(valid_set), type(test_set))\n",
    "print(type(train_set[0]), type(valid_set[0]), type(test_set[0]))\n",
    "print(len(train_set), len(valid_set), len(test_set)) \n",
    "print(type(train_set[1]), type(valid_set[1]), type(test_set[1]))\n",
    "print(train_set[0].shape, valid_set[0].shape, test_set[0].shape)\n",
    "print(train_set[1].shape, valid_set[1].shape, test_set[1].shape)\n",
    " #preparing data \n",
    "trainset=train_set[0]\n",
    "trainsettarget=train_set[1]\n",
    "validationset=valid_set[0]\n",
    "validationsettarget=valid_set[1] \n",
    "testset=test_set[0]\n",
    "testsettarget=test_set[1]\n",
    " #mergingtraingset and validationset in trainingset \n",
    "trainset=numpy.concatenate((trainset,validationset),axis=0) \n",
    "trainsettarget=numpy.concatenate((trainsettarget,validationsettarget),axis=0)\n",
    " #normalization in the range 0-1\n",
    "trainset=trainset/255. \n",
    "testset=testset/255.\n",
    " #creating instance of the classifier \n",
    "mlp = MLPClassifier(hidden_layer_sizes=(784,), max_iter=10, solver='adam', learning_rate_init=0.1, verbose=10)\n",
    " #train the model \n",
    "mlp.fit(trainset,trainsettarget)\n",
    " #predict using the learnt classifier\n",
    "prediction=mlp.predict(testset)\n",
    "print(\"############### Predictions #################\")\n",
    "print(prediction) \n",
    "print(\"#############################################\")\n",
    "print(\"Accuracy =\",metrics.accuracy_score(testsettarget, prediction, normalize=True))\n",
    "print(clf.predict_proba(testset));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
